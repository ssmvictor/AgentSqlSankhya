# üìö Sistema de Indexa√ß√£o do Schema Sankhya

Sistema inteligente de indexa√ß√£o e otimiza√ß√£o do dicion√°rio de dados Sankhya para uso eficiente com APIs de LLM.

## üéØ Problema Resolvido

O arquivo `sankhya_schema.md` cont√©m:
- **100+ tabelas**
- **1000+ campos**
- **Milhares de linhas** de documenta√ß√£o

Enviar tudo isso para a API seria:
- ‚ùå Caro (muitos tokens)
- ‚ùå Lento (processamento demorado)
- ‚ùå Ineficiente (informa√ß√£o desnecess√°ria)

## ‚ú® Solu√ß√£o: Indexa√ß√£o Inteligente

### 1. **SchemaIndexer** - Indexa√ß√£o e Cache
```python
from schema_indexer import SchemaIndexer

# Inicializa e indexa automaticamente
indexer = SchemaIndexer("sankhya_schema.md")

# Buscar tabela espec√≠fica
tabela = indexer.buscar_tabela("TGFCAB")

# Buscar campo em todas as tabelas
campos = indexer.buscar_campo("NUNOTA")

# Identificar tabelas relevantes para uma query
tabelas = indexer.identificar_tabelas_relevantes("pedidos de venda em aberto")
```

### 2. **SchemaOptimizer** - Otimiza√ß√£o de Contexto
```python
from schema_optimizer import SchemaOptimizer

optimizer = SchemaOptimizer(indexer, max_tokens=2000)

# Otimizar contexto para query espec√≠fica
resultado = optimizer.otimizar_para_query(
    "relat√≥rio de vendas com parceiros",
    estrategia='smart'  # ou 'minimal', 'compact', 'full'
)

print(f"Tokens usados: {resultado['tokens_estimados']}")
print(f"Tabelas inclu√≠das: {resultado['tabelas_incluidas']}")
```

## üöÄ Instala√ß√£o

### 1. Instalar depend√™ncias
```bash
pip install agno python-dotenv tiktoken
```

### 2. Estrutura de pastas
```
projeto/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ sankhya_schema.md
‚îÇ   ‚îú‚îÄ‚îÄ instrucoes_ia.md
‚îÇ   ‚îî‚îÄ‚îÄ exemplos_de_uso.md
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ schema_indexer.py
‚îÇ   ‚îú‚îÄ‚îÄ schema_optimizer.py
‚îÇ   ‚îî‚îÄ‚îÄ agno_sankhya_agent.py
‚îú‚îÄ‚îÄ .cache/              # Cache autom√°tico (criado automaticamente)
‚îÇ   ‚îú‚îÄ‚îÄ schema_index.pkl
‚îÇ   ‚îî‚îÄ‚îÄ schema_hash.txt
‚îî‚îÄ‚îÄ .env
```

### 3. Configurar .env
```env
GROK_API_KEY=sua_chave_aqui
```

## üìä Como Funciona

### Fluxo de Processamento

```mermaid
graph LR
    A[Query Usu√°rio] --> B[Identificar Contexto]
    B --> C[Selecionar Tabelas]
    C --> D[Filtrar Campos]
    D --> E[Otimizar Tokens]
    E --> F[Enviar para API]
```

### Estrat√©gias de Otimiza√ß√£o

| Estrat√©gia | Tokens | Detalhamento | Uso Ideal |
|------------|--------|--------------|-----------|
| `minimal` | ~200-500 | Apenas campos-chave | Queries simples |
| `compact` | ~500-1000 | Formato resumido | Queries m√©dias |
| `smart` | ~1000-2000 | An√°lise inteligente | Autom√°tico/Recomendado |
| `full` | ~2000+ | Todos os detalhes | Queries complexas |

## üí° Exemplos de Uso

### Exemplo 1: Query Simples
```python
from schema_indexer import SchemaIndexer
from schema_optimizer import SchemaOptimizer

# Inicializar
indexer = SchemaIndexer("sankhya_schema.md")
optimizer = SchemaOptimizer(indexer)

# Query simples
query = "listar parceiros"
resultado = optimizer.otimizar_para_query(query, estrategia='minimal')

print(resultado['contexto'])
# Sa√≠da: Apenas tabela TGFPAR com campos principais
```

### Exemplo 2: Query Complexa
```python
# Query complexa com JOINs
query = "relat√≥rio de vendas com produtos, parceiros e impostos"
resultado = optimizer.otimizar_para_query(query, estrategia='smart')

print(f"Tabelas identificadas: {resultado['tabelas_incluidas']}")
# Sa√≠da: ['TGFCAB', 'TGFITE', 'TGFPAR', 'TGFDIN']

print(f"Tokens estimados: {resultado['tokens_estimados']}")
# Sa√≠da: ~1500 tokens (ao inv√©s de 50000+ do arquivo completo)
```

### Exemplo 3: Com Agno Framework
```python
from agno_sankhya_agent import SankhyaSQLAssistant

assistant = SankhyaSQLAssistant()

resultado = assistant.processar_query(
    "crie um SQL para pedidos em aberto com rentabilidade"
)

print(resultado['sql_gerado'])
```

## üîç Funcionalidades Principais

### 1. **Cache Inteligente**
- Detecta mudan√ßas no arquivo
- Carrega √≠ndices instantaneamente
- Economiza tempo de processamento

### 2. **Busca Indexada**
- Busca por tabela: O(1)
- Busca por campo: O(1) 
- Busca por palavra-chave: O(n)

### 3. **An√°lise de Query**
- Detecta complexidade
- Identifica JOINs necess√°rios
- Reconhece campos mencionados

### 4. **Otimiza√ß√£o de Tokens**
- Redu√ß√£o de 95%+ dos tokens
- Mant√©m informa√ß√£o relevante
- Adapta-se ao contexto

## üìà M√©tricas de Performance

| Opera√ß√£o | Sem Indexa√ß√£o | Com Indexa√ß√£o | Melhoria |
|----------|---------------|---------------|----------|
| Carregar schema | 5-10s | <0.1s (cache) | 100x |
| Buscar tabela | O(n) scan | O(1) lookup | ‚àû |
| Tokens para API | 50.000+ | 500-2000 | 25-100x |
| Custo por query | $0.50+ | $0.01-0.05 | 10-50x |

## üõ†Ô∏è API Reference

### SchemaIndexer

```python
# M√©todos principais
indexer.buscar_tabela(nome: str) -> Tabela
indexer.buscar_campo(nome: str) -> List[Dict]
indexer.buscar_tabelas_por_palavra(palavra: str) -> List[str]
indexer.identificar_tabelas_relevantes(query: str) -> List[str]
indexer.get_contexto_minimo(tabelas: List[str]) -> str
indexer.get_estatisticas() -> Dict
```

### SchemaOptimizer

```python
# M√©todos principais
optimizer.otimizar_para_query(query: str, estrategia: str) -> Dict
optimizer.contar_tokens(texto: str) -> int
optimizer.gerar_contexto_com_exemplos(query: str) -> str
optimizer.salvar_estatisticas(filepath: str)
```

## üêõ Troubleshooting

### Cache n√£o atualiza
```bash
# Limpar cache manualmente
rm -rf .cache/
```

### Erro de encoding
```python
# For√ßar UTF-8
indexer = SchemaIndexer("sankhya_schema.md", encoding='utf-8')
```

### Tokens excedidos
```python
# Reduzir limite de tokens
optimizer = SchemaOptimizer(indexer, max_tokens=1000)
```

## üìù Notas de Desenvolvimento

### Por que usar pickle para cache?
- **Velocidade**: 100x mais r√°pido que JSON
- **Preserva estrutura**: Mant√©m objetos Python complexos
- **Compacto**: Menor tamanho de arquivo

### Por que indexar por palavra?
- **Busca sem√¢ntica**: Encontra tabelas relacionadas
- **Flexibilidade**: Usu√°rio n√£o precisa saber nome exato
- **Performance**: Pr√©-computado no cache

### Estimativa de tokens
- Usa `tiktoken` quando dispon√≠vel (preciso)
- Fallback: 1 token ‚âà 4 caracteres (aproximado)

## üö¶ Pr√≥ximos Passos

- [ ] Adicionar suporte a embeddings para busca sem√¢ntica
- [ ] Implementar cache distribu√≠do (Redis)
- [ ] Criar interface web para visualiza√ß√£o
- [ ] Adicionar mais estrat√©gias de otimiza√ß√£o
- [ ] Suporte a m√∫ltiplos idiomas

## üìÑ Licen√ßa

MIT - Use como quiser!

## ü§ù Contribuindo

PRs s√£o bem-vindos! Para mudan√ßas grandes, abra uma issue primeiro.

---

**Desenvolvido com ‚ù§Ô∏è para otimizar custos e performance com LLMs**